{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32954d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score, classification_report, log_loss\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "941183d3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9327827",
   "metadata": {},
   "source": [
    "## visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5e6af39d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 15 artists>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "size0 = []\n",
    "for i in range(16):\n",
    "    if i == 10: \n",
    "        continue\n",
    "    size0.append(len(os.listdir(f'dataset0/train/class{i}'))) \n",
    "    \n",
    "plt.bar(np.arange(15), size0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "de0a6170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 11 artists>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "size1 = []\n",
    "for i in range(11):\n",
    "    size1.append(len(os.listdir(f'dataset1/train/class{i}'))) \n",
    "    \n",
    "plt.bar(np.arange(11), size1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc52b643",
   "metadata": {},
   "source": [
    "# set data\n",
    "- dataset1 의 전이 학습을 위해 train/validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "12c1dfbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['class0' 'class1' 'class11' 'class12' 'class13' 'class14' 'class15'\n",
      " 'class2' 'class3' 'class4' 'class5' 'class6' 'class7' 'class8' 'class9']\n",
      "['class0' 'class1' 'class10' 'class2' 'class3' 'class4' 'class5' 'class6'\n",
      " 'class7' 'class8' 'class9']\n"
     ]
    }
   ],
   "source": [
    "dataset0_classes = os.listdir('dataset0/train/')\n",
    "dataset0_label_encoder = LabelEncoder()\n",
    "\n",
    "dataset0_label_encoder.fit(dataset0_classes)\n",
    "print(dataset0_label_encoder.classes_)\n",
    "\n",
    "dataset1_classes = os.listdir('dataset1/train/')\n",
    "dataset1_label_encoder = LabelEncoder()\n",
    "\n",
    "dataset1_label_encoder.fit(dataset1_classes)\n",
    "print(dataset1_label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "866e6cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset0_dir = 'dataset0/'\n",
    "dataset1_dir = 'dataset1/'\n",
    "\n",
    "dataset0_train_dir = dataset0_dir + 'train/'\n",
    "dataset0_test_dir = dataset0_dir + 'test/'\n",
    "\n",
    "dataset1_train_dir = dataset1_dir + 'train/'\n",
    "dataset1_val_dir = dataset1_dir + 'val/'\n",
    "dataset1_test_dir = dataset1_dir + 'test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e39c5a6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# split train/val for dataset1\n",
    "\n",
    "os.mkdir(dataset1_val_dir)\n",
    "for cls in dataset1_classes:\n",
    "    os.mkdir(os.path.join(dataset1_val_dir, cls))\n",
    "    \n",
    "for i in range(11):\n",
    "    num_ratio = int(0.2 * len(os.listdir(f'dataset1/train/class{i}')))\n",
    "    mv_files = random.sample(os.listdir(f'dataset1/train/class{i}'), num_ratio)\n",
    "    for mf in mv_files:\n",
    "        os.rename(f'dataset1/train/class{i}/{mf}', f'dataset1/val/class{i}/{mf}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d245373",
   "metadata": {},
   "source": [
    "directory structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5dd391",
   "metadata": {},
   "source": [
    "```\n",
    "main/\n",
    "|-- programmers_dev-matching_yunsoo-woo_final.ipynb\n",
    "|-- dataset0/\n",
    "|   |-- train/\n",
    "|   |   |-- class0/\n",
    "|   |   |   |-- 0.csv\n",
    "|   |   |   |-- 1.csv\n",
    "|   |   |   |-- ...\n",
    "|   |   |-- class1/\n",
    "|   |   |-- ...\n",
    "|   |   |-- class15/\n",
    "|   |-- test/\n",
    "|   |   |-- class0/\n",
    "|   |   |-- class1/\n",
    "|   |   |-- ...\n",
    "|   |   |-- class15/\n",
    "|-- dataset1/\n",
    "|   |-- train/\n",
    "|   |   |-- class0/\n",
    "|   |   |   |-- 0.csv\n",
    "|   |   |   |-- 1.csv\n",
    "|   |   |   |-- ...\n",
    "|   |   |-- class1/\n",
    "|   |   |-- ...\n",
    "|   |   |-- class15/\n",
    "|   |-- val/\n",
    "|   |   |-- class0/\n",
    "|   |   |-- class1/\n",
    "|   |   |-- ...\n",
    "|   |   |-- class15/\n",
    "|   |-- test/\n",
    "|   |   |-- 103.csv\n",
    "|   |   |-- ...\n",
    "|   |   |-- 869.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb3eac4",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "d956b4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 개수가 많은 label 데이터에 대해 over-sampling\n",
    "# augmentation은 training 데이터에만 적용\n",
    "\n",
    "def create_dataset_resampled(dataset_dir):\n",
    "    X, y = [], []\n",
    "    labels = os.listdir(dataset_dir)\n",
    "    labels = sorted(labels)\n",
    "    for label in labels:\n",
    "        file_list = os.listdir(dataset_dir + label + '/')\n",
    "        for f in file_list:\n",
    "            temp = pd.read_csv(dataset_dir + label + '/' + f)\n",
    "            X.append(torch.from_numpy(temp.values))\n",
    "            \n",
    "    new_X = []\n",
    "    length = [len(os.listdir(dataset_dir + label + '/')) for label in labels]\n",
    "    n_samples = max(length)\n",
    "    max_idex = length.index(n_samples)\n",
    "    length.insert(0, 0)\n",
    "    for r in range(len(labels)):\n",
    "        start = length[r]\n",
    "        end = start + length[r+1]\n",
    "        if r == max_idex:\n",
    "            new_X += X[start:end]\n",
    "        else:\n",
    "            new_X += resample(X[start:end], n_samples=n_samples)\n",
    "    X = pad_sequence(new_X, batch_first=True) # B x T x *\n",
    "    \n",
    "    y = []\n",
    "    for label in labels:\n",
    "        for d in range(n_samples):\n",
    "            y.append(label)\n",
    "            \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "40d7b9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset_dir):\n",
    "    X, y = [], []\n",
    "    labels = os.listdir(dataset_dir)\n",
    "    for label in labels:\n",
    "        file_list = os.listdir(dataset_dir + label + '/')\n",
    "        for f in file_list:\n",
    "            temp = pd.read_csv(dataset_dir + label + '/' + f)\n",
    "            X.append(torch.from_numpy(temp.values))\n",
    "            y.append(label)\n",
    "    X = pad_sequence(X, batch_first=True) # B x T x *\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "9b907549",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bernice/miniconda3/envs/romp-env/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "/home/bernice/miniconda3/envs/romp-env/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "dataset0_X_train, dataset0_y_train = create_dataset(dataset0_train_dir)\n",
    "dataset0_y_train = dataset0_label_encoder.transform(dataset0_y_train)\n",
    "\n",
    "dataset0_X_test, dataset0_y_test = create_dataset(dataset0_test_dir)\n",
    "dataset0_y_test = dataset0_label_encoder.transform(dataset0_y_test)\n",
    "\n",
    "dataset0_train_dataset = TensorDataset(torch.tensor(dataset0_X_train).float(), torch.from_numpy(dataset0_y_train))\n",
    "dataset0_test_dataset = TensorDataset(torch.tensor(dataset0_X_test).float(), torch.from_numpy(dataset0_y_test))\n",
    "\n",
    "dataset0_train_dataloader = DataLoader(dataset0_train_dataset,\n",
    "                                       batch_size=batch_size)\n",
    "dataset0_test_dataloader= DataLoader(dataset0_test_dataset,\n",
    "                                     batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "d8f3df7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bernice/miniconda3/envs/romp-env/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/home/bernice/miniconda3/envs/romp-env/lib/python3.7/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "dataset1_X_train, dataset1_y_train = create_dataset(dataset1_train_dir)\n",
    "dataset1_y_train = dataset1_label_encoder.transform(dataset1_y_train)\n",
    "\n",
    "dataset1_X_val, dataset1_y_val = create_dataset(dataset1_val_dir)\n",
    "dataset1_y_val = dataset1_label_encoder.transform(dataset1_y_val)\n",
    "\n",
    "dataset1_train_dataset = TensorDataset(torch.tensor(dataset1_X_train).float(), torch.from_numpy(dataset1_y_train))\n",
    "dataset1_train_dataloader = DataLoader(dataset1_train_dataset,\n",
    "                                       batch_size=batch_size)\n",
    "\n",
    "dataset1_val_dataset = TensorDataset(torch.tensor(dataset1_X_val).float(), torch.from_numpy(dataset1_y_val))\n",
    "dataset1_val_dataloader = DataLoader(dataset1_val_dataset,\n",
    "                                       batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "8695c11c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bernice/miniconda3/envs/romp-env/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "dataset1_test_X = []\n",
    "test_list = os.listdir(dataset1_test_dir)\n",
    "for f in test_list:\n",
    "    temp = pd.read_csv(dataset1_test_dir + f)\n",
    "    dataset1_test_X.append(torch.from_numpy(temp.values))\n",
    "\n",
    "dataset1_test_X = pad_sequence(dataset1_test_X, batch_first=True)\n",
    "dataset1_test_dataset = TensorDataset(torch.tensor(dataset1_test_X, device='cuda:0'))\n",
    "dataset1_test_dataloader = DataLoader(dataset1_test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4810f46",
   "metadata": {},
   "source": [
    "# define Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5007b11a",
   "metadata": {},
   "source": [
    "`GRU 모델`\n",
    "- 입력과 출력을 연속된 단위로 처리하는 순환 신경망 모델. 이전 출력값이 다음 입력으로 연결되기 때문에 시계열 데이터에 적합하다.\n",
    "- 2014년에 발표된 GRU 모델은 출력 게이트를 생략해 간결한 구조를 가진다.\n",
    "\n",
    "`custom`\n",
    "- 3-stacked GRU + linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "21b5ef03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyGRU(\n",
      "  (gru): GRU(6, 300, num_layers=3, batch_first=True)\n",
      "  (relu): ReLU()\n",
      "  (linear1): Linear(in_features=300, out_features=128, bias=True)\n",
      "  (linear2): Linear(in_features=128, out_features=15, bias=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "lr = 0.0001\n",
    "epochs = 500\n",
    "\n",
    "class MyGRU(nn.Module):\n",
    "    def __init__(self, nfea, nhid, nlabel, out_dropout):\n",
    "        super(MyGRU, self).__init__()\n",
    "        self.gru = torch.nn.GRU(nfea, nhid, num_layers=3, batch_first=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear1 = nn.Linear(nhid, 128)\n",
    "        self.linear2 = nn.Linear(128, nlabel)\n",
    "        self.dropout = nn.Dropout(out_dropout)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bsz, time, features = x.shape \n",
    "        x, _ = self.gru(x.view(bsz, time, features))\n",
    "        x = self.dropout(self.linear1(self.relu(x[:,-1,:])))\n",
    "        output = self.linear2(self.relu(x))\n",
    "        return output\n",
    "\n",
    "nfea = 6\n",
    "nhid = 300\n",
    "nlabel = 15\n",
    "dropout = 0.3\n",
    "\n",
    "model = MyGRU(nfea, nhid, nlabel, dropout).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "7ad0d35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.init as init\n",
    "\n",
    "for param in model.parameters():\n",
    "    if len(param.shape) >= 2:\n",
    "        init.orthogonal_(param.data)\n",
    "    else:\n",
    "        init.normal_(param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "ddbc0fad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206/206 [00:27<00:00,  7.43batch/s, train_acc=0.0646, train_logloss=3.67, train_loss=3.64]\n",
      "Valid Epoch 0: 100%|██████████| 28/28 [00:01<00:00, 25.47batch/s, valid_acc=0.0766, valid_logloss=2.77, valid_loss=4.41]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 4.40536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206/206 [00:27<00:00,  7.57batch/s, train_acc=0.0481, train_logloss=3.28, train_loss=3.29]\n",
      "Valid Epoch 1: 100%|██████████| 28/28 [00:01<00:00, 26.41batch/s, valid_acc=0.0766, valid_logloss=2.74, valid_loss=3.72]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 3.71708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206/206 [00:27<00:00,  7.59batch/s, train_acc=0.0257, train_logloss=3.2, train_loss=2.71] \n",
      "Valid Epoch 2: 100%|██████████| 28/28 [00:01<00:00, 26.21batch/s, valid_acc=0.0766, valid_logloss=2.83, valid_loss=3.34]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 3.33816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206/206 [00:27<00:00,  7.52batch/s, train_acc=0.0323, train_logloss=3.16, train_loss=1.8] \n",
      "Valid Epoch 3: 100%|██████████| 28/28 [00:01<00:00, 25.65batch/s, valid_acc=0.0335, valid_logloss=2.91, valid_loss=4.2] \n",
      "100%|██████████| 206/206 [00:27<00:00,  7.53batch/s, train_acc=0.199, train_logloss=2.75, train_loss=1.29]\n",
      "Valid Epoch 4: 100%|██████████| 28/28 [00:01<00:00, 25.61batch/s, valid_acc=0.0335, valid_logloss=3.5, valid_loss=4.19] \n",
      "100%|██████████| 206/206 [00:27<00:00,  7.54batch/s, train_acc=0.0457, train_logloss=3.22, train_loss=2.63]\n",
      "Valid Epoch 5: 100%|██████████| 28/28 [00:01<00:00, 25.92batch/s, valid_acc=0.0766, valid_logloss=2.75, valid_loss=4.11]\n",
      "100%|██████████| 206/206 [00:27<00:00,  7.53batch/s, train_acc=0.0201, train_logloss=3.08, train_loss=2.36]\n",
      "Valid Epoch 6: 100%|██████████| 28/28 [00:01<00:00, 26.21batch/s, valid_acc=0.0766, valid_logloss=2.88, valid_loss=3.69]\n",
      "100%|██████████| 206/206 [00:27<00:00,  7.56batch/s, train_acc=0.0269, train_logloss=3.09, train_loss=2.35]\n",
      "Valid Epoch 7: 100%|██████████| 28/28 [00:01<00:00, 23.86batch/s, valid_acc=0.0335, valid_logloss=2.8, valid_loss=3.28] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 3.27529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206/206 [00:27<00:00,  7.45batch/s, train_acc=0.0231, train_logloss=3.04, train_loss=2.26]\n",
      "Valid Epoch 8: 100%|██████████| 28/28 [00:01<00:00, 25.53batch/s, valid_acc=0.0335, valid_logloss=2.77, valid_loss=3.05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 3.04519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206/206 [00:27<00:00,  7.54batch/s, train_acc=0.0187, train_logloss=3, train_loss=2.35]   \n",
      "Valid Epoch 9: 100%|██████████| 28/28 [00:01<00:00, 26.06batch/s, valid_acc=0.0335, valid_logloss=2.83, valid_loss=3.01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 3.01479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206/206 [00:27<00:00,  7.59batch/s, train_acc=0.0639, train_logloss=2.85, train_loss=2.33] \n",
      "Valid Epoch 10: 100%|██████████| 28/28 [00:01<00:00, 26.39batch/s, valid_acc=0.0335, valid_logloss=2.78, valid_loss=3.07]\n",
      "100%|██████████| 206/206 [00:27<00:00,  7.55batch/s, train_acc=0.0665, train_logloss=2.84, train_loss=2.35] \n",
      "Valid Epoch 11: 100%|██████████| 28/28 [00:01<00:00, 26.52batch/s, valid_acc=0.0335, valid_logloss=2.75, valid_loss=3.11]\n",
      "100%|██████████| 206/206 [00:27<00:00,  7.58batch/s, train_acc=0.0653, train_logloss=2.84, train_loss=2.39]\n",
      "Valid Epoch 12: 100%|██████████| 28/28 [00:01<00:00, 26.23batch/s, valid_acc=0.0335, valid_logloss=2.73, valid_loss=3.11]\n",
      "100%|██████████| 206/206 [00:27<00:00,  7.50batch/s, train_acc=0.0646, train_logloss=2.86, train_loss=2.4] \n",
      "Valid Epoch 13: 100%|██████████| 28/28 [00:01<00:00, 26.27batch/s, valid_acc=0.0335, valid_logloss=2.73, valid_loss=3.07]\n",
      "100%|██████████| 206/206 [00:27<00:00,  7.56batch/s, train_acc=0.0534, train_logloss=2.87, train_loss=2.45]\n",
      "Valid Epoch 14: 100%|██████████| 28/28 [00:01<00:00, 26.38batch/s, valid_acc=0.0335, valid_logloss=2.74, valid_loss=3.01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 3.00883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206/206 [00:27<00:00,  7.56batch/s, train_acc=0.0456, train_logloss=2.89, train_loss=2.48]\n",
      "Valid Epoch 15: 100%|██████████| 28/28 [00:01<00:00, 26.30batch/s, valid_acc=0.0335, valid_logloss=2.75, valid_loss=2.95]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.94923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206/206 [00:27<00:00,  7.57batch/s, train_acc=0.0338, train_logloss=2.91, train_loss=2.53]\n",
      "Valid Epoch 16: 100%|██████████| 28/28 [00:01<00:00, 25.95batch/s, valid_acc=0.0335, valid_logloss=2.77, valid_loss=2.92]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.91918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206/206 [00:27<00:00,  7.59batch/s, train_acc=0.0302, train_logloss=2.92, train_loss=2.53]\n",
      "Valid Epoch 17: 100%|██████████| 28/28 [00:01<00:00, 26.19batch/s, valid_acc=0.0335, valid_logloss=2.8, valid_loss=2.9]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.90179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206/206 [00:27<00:00,  7.49batch/s, train_acc=0.0193, train_logloss=2.93, train_loss=2.12]\n",
      "Valid Epoch 18: 100%|██████████| 28/28 [00:01<00:00, 25.27batch/s, valid_acc=0.0335, valid_logloss=3.04, valid_loss=2.83]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.83258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206/206 [00:27<00:00,  7.57batch/s, train_acc=0.166, train_logloss=3, train_loss=2.09]    \n",
      "Valid Epoch 19: 100%|██████████| 28/28 [00:01<00:00, 26.02batch/s, valid_acc=0.0335, valid_logloss=2.76, valid_loss=4.37]\n",
      "100%|██████████| 206/206 [00:27<00:00,  7.63batch/s, train_acc=0.0653, train_logloss=2.98, train_loss=2.06]\n",
      "Valid Epoch 20: 100%|██████████| 28/28 [00:01<00:00, 26.48batch/s, valid_acc=0.0335, valid_logloss=2.71, valid_loss=4.25]\n",
      "100%|██████████| 206/206 [00:27<00:00,  7.56batch/s, train_acc=0.0646, train_logloss=2.94, train_loss=2.14]\n",
      "Valid Epoch 21: 100%|██████████| 28/28 [00:01<00:00, 25.98batch/s, valid_acc=0.0335, valid_logloss=2.71, valid_loss=4.06]\n",
      "100%|██████████| 206/206 [00:27<00:00,  7.59batch/s, train_acc=0.0642, train_logloss=2.92, train_loss=2.17]\n",
      "Valid Epoch 22: 100%|██████████| 28/28 [00:01<00:00, 26.99batch/s, valid_acc=0.0335, valid_logloss=2.73, valid_loss=3.82]\n",
      "100%|██████████| 206/206 [00:27<00:00,  7.51batch/s, train_acc=0.0501, train_logloss=2.93, train_loss=2.23]\n",
      "Valid Epoch 23: 100%|██████████| 28/28 [00:01<00:00, 26.38batch/s, valid_acc=0.0335, valid_logloss=2.76, valid_loss=3.55]\n",
      "100%|██████████| 206/206 [00:27<00:00,  7.56batch/s, train_acc=0.0504, train_logloss=2.86, train_loss=2.17]\n",
      "Valid Epoch 24: 100%|██████████| 28/28 [00:01<00:00, 26.44batch/s, valid_acc=0.0335, valid_logloss=2.81, valid_loss=3.33]\n",
      "100%|██████████| 206/206 [00:27<00:00,  7.57batch/s, train_acc=0.0199, train_logloss=3.04, train_loss=2.47]\n",
      "Valid Epoch 25: 100%|██████████| 28/28 [00:01<00:00, 26.47batch/s, valid_acc=0.24, valid_logloss=2.65, valid_loss=3.96] \n",
      "100%|██████████| 206/206 [00:27<00:00,  7.59batch/s, train_acc=0.0203, train_logloss=2.96, train_loss=2.47]\n",
      "Valid Epoch 26: 100%|██████████| 28/28 [00:01<00:00, 26.18batch/s, valid_acc=0.0335, valid_logloss=2.67, valid_loss=3.71]\n",
      "100%|██████████| 206/206 [00:27<00:00,  7.59batch/s, train_acc=0.101, train_logloss=2.67, train_loss=0.816] \n",
      "Valid Epoch 27: 100%|██████████| 28/28 [00:01<00:00, 26.31batch/s, valid_acc=0.0335, valid_logloss=3.51, valid_loss=3.93]\n",
      "100%|██████████| 206/206 [00:27<00:00,  7.58batch/s, train_acc=0.196, train_logloss=2.67, train_loss=2.51] \n",
      "Valid Epoch 28: 100%|██████████| 28/28 [00:01<00:00, 25.93batch/s, valid_acc=0.0266, valid_logloss=2.58, valid_loss=4.09]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EARLY_STOPPING!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_models = []\n",
    "\n",
    "EARLY_STOPPING_EPOCH = 10\n",
    "seed = 777\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "random.seed(seed)\n",
    "\n",
    "softmax = torch.nn.Softmax(-1)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "lr_sched = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=1, eta_min=0.001, last_epoch=-1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "valid_acc_max = 0\n",
    "valid_early_stop = 0\n",
    "valid_best_loss = float('inf')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_acc_list = []\n",
    "    train_logloss_list = []\n",
    "    with tqdm(dataset0_train_dataloader, total=dataset0_train_dataloader.__len__(), unit=\"batch\") as train_bar:\n",
    "        for sample in train_bar:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            datas, labels = sample\n",
    "            datas = datas.to(device)\n",
    "            labels = labels.to(dtype=torch.long).to(device)\n",
    "            model.train()\n",
    "            with torch.set_grad_enabled(True):\n",
    "                outputs = model(datas)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # log loss\n",
    "                probs = softmax(outputs)\n",
    "                refs = labels.cpu().detach().clone().numpy()\n",
    "                probs = probs.cpu().detach().clone().numpy()\n",
    "                logloss = log_loss(refs, probs, labels = np.arange(0,nlabel))\n",
    "                train_logloss_list.append(logloss)\n",
    "                train_logloss = np.mean(train_logloss_list)\n",
    "\n",
    "                preds = torch.argmax(outputs, dim = 1)\n",
    "                preds = preds.cpu().detach().numpy()\n",
    "                refs = labels.cpu().detach().numpy()\n",
    "                \n",
    "                batch_acc = (refs == preds).mean()\n",
    "                train_acc_list.append(batch_acc)\n",
    "                train_acc = np.mean(train_acc_list)\n",
    "                \n",
    "            train_bar.set_postfix(train_loss= loss.item(), train_acc = train_acc, train_logloss = train_logloss)\n",
    "            \n",
    "       \n",
    "    valid_acc_list = []\n",
    "    valid_logloss_list = []\n",
    "    with tqdm(dataset0_test_dataloader, total=dataset0_test_dataloader.__len__(), unit=\"batch\") as valid_bar:\n",
    "        for sample in valid_bar:\n",
    "            valid_bar.set_description(f\"Valid Epoch {epoch}\")\n",
    "            optimizer.zero_grad()\n",
    "            datas, labels = sample\n",
    "            datas = datas.to(device)\n",
    "            labels = labels.to(dtype=torch.long).to(device)\n",
    "\n",
    "            model.eval()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(datas) # bsz, nlabel\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # log loss\n",
    "                probs = softmax(outputs)\n",
    "                refs = labels.cpu().detach().clone().numpy()\n",
    "                probs = probs.cpu().detach().clone().numpy()\n",
    "                logloss = log_loss(refs, probs, labels = np.arange(0,nlabel))\n",
    "                valid_logloss_list.append(logloss)\n",
    "                valid_logloss = np.mean(valid_logloss_list)\n",
    "\n",
    "                preds = torch.argmax(outputs, dim = 1)\n",
    "                preds = preds.cpu().detach().numpy()\n",
    "                refs = labels.cpu().detach().numpy()\n",
    "                batch_acc = (refs == preds).mean()\n",
    "                valid_acc_list.append(batch_acc)\n",
    "                valid_acc = np.mean(valid_acc_list)\n",
    "\n",
    "            valid_bar.set_postfix(valid_loss= loss.item(), valid_acc = valid_acc, valid_logloss = valid_logloss)\n",
    "            \n",
    "    # early stopping\n",
    "    if loss.item() < valid_best_loss:\n",
    "        print(f\"\\nBEST VALID LOSS : {loss.item():.5f}\")\n",
    "        valid_best_loss = loss.item()\n",
    "        valid_early_stop = 0\n",
    "    else:\n",
    "        valid_early_stop += 1\n",
    "        if valid_early_stop >= EARLY_STOPPING_EPOCH:\n",
    "            print(\"\\nEARLY_STOPPING!!\")\n",
    "            break\n",
    "            \n",
    "    lr_sched.step()\n",
    "    \n",
    "    if valid_acc_max < valid_acc:\n",
    "        valid_acc_max = valid_acc\n",
    "        best_model = model\n",
    "        torch.save(best_model.state_dict(), f'./pretrained_best_model.pth')\n",
    "\n",
    "    best_models.append(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc694950",
   "metadata": {},
   "source": [
    "# freeze and transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "b8c71aab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 11개 클래스 분류를 위한 레이어 추가\n",
    "\n",
    "model = MyGRU(nfea, nhid, nlabel, dropout).to(device)\n",
    "model.load_state_dict(torch.load('pretrained_best_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "trans_model = nn.Sequential(\n",
    "    model,\n",
    "    nn.Linear(nlabel, 11)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "c2803b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마지막 레이어만 파라미터 init + 훈련\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if name in ['linear.0.weight', '0.linear1.bias', '0.linear2.bias', 'linear.2.weight']:\n",
    "        param.requires_grad = True\n",
    "        if len(param.shape) >= 2:\n",
    "            init.orthogonal_(param.data)\n",
    "        else:\n",
    "            init.normal_(param.data)\n",
    "    else:\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "eb6bc398",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.61batch/s, train_acc=0.0859, train_logloss=2.5, train_loss=2.6]  \n",
      "Valid Epoch 0: 100%|██████████| 2/2 [00:00<00:00, 28.19batch/s, valid_acc=0.129, valid_logloss=2.6, valid_loss=2.81]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.81297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 23.23batch/s, train_acc=0.0885, train_logloss=2.49, train_loss=2.54]\n",
      "Valid Epoch 1: 100%|██████████| 2/2 [00:00<00:00, 27.53batch/s, valid_acc=0.129, valid_logloss=2.6, valid_loss=2.81]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.80867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.82batch/s, train_acc=0.0649, train_logloss=2.5, train_loss=2.67] \n",
      "Valid Epoch 2: 100%|██████████| 2/2 [00:00<00:00, 27.58batch/s, valid_acc=0.129, valid_logloss=2.59, valid_loss=2.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.80214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.98batch/s, train_acc=0.0894, train_logloss=2.49, train_loss=2.64]\n",
      "Valid Epoch 3: 100%|██████████| 2/2 [00:00<00:00, 28.09batch/s, valid_acc=0.129, valid_logloss=2.59, valid_loss=2.79]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.79248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 23.21batch/s, train_acc=0.0894, train_logloss=2.48, train_loss=2.54]\n",
      "Valid Epoch 4: 100%|██████████| 2/2 [00:00<00:00, 28.65batch/s, valid_acc=0.129, valid_logloss=2.58, valid_loss=2.78]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.77880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 23.09batch/s, train_acc=0.0894, train_logloss=2.48, train_loss=2.57]\n",
      "Valid Epoch 5: 100%|██████████| 2/2 [00:00<00:00, 28.21batch/s, valid_acc=0.129, valid_logloss=2.57, valid_loss=2.76]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.76084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 23.18batch/s, train_acc=0.0894, train_logloss=2.48, train_loss=2.68]\n",
      "Valid Epoch 6: 100%|██████████| 2/2 [00:00<00:00, 28.42batch/s, valid_acc=0.129, valid_logloss=2.56, valid_loss=2.74]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.73950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 23.08batch/s, train_acc=0.0894, train_logloss=2.47, train_loss=2.6] \n",
      "Valid Epoch 7: 100%|██████████| 2/2 [00:00<00:00, 28.06batch/s, valid_acc=0.129, valid_logloss=2.55, valid_loss=2.72]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.71686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 23.18batch/s, train_acc=0.0894, train_logloss=2.46, train_loss=2.54]\n",
      "Valid Epoch 8: 100%|██████████| 2/2 [00:00<00:00, 27.91batch/s, valid_acc=0.129, valid_logloss=2.54, valid_loss=2.69]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.69236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 23.01batch/s, train_acc=0.0894, train_logloss=2.45, train_loss=2.55]\n",
      "Valid Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 28.14batch/s, valid_acc=0.129, valid_logloss=2.53, valid_loss=2.67]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.66819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 23.02batch/s, train_acc=0.0894, train_logloss=2.45, train_loss=2.65]\n",
      "Valid Epoch 10: 100%|██████████| 2/2 [00:00<00:00, 28.41batch/s, valid_acc=0.129, valid_logloss=2.53, valid_loss=2.67]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.66569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 21.40batch/s, train_acc=0.0894, train_logloss=2.44, train_loss=2.58]\n",
      "Valid Epoch 11: 100%|██████████| 2/2 [00:00<00:00, 19.21batch/s, valid_acc=0.129, valid_logloss=2.52, valid_loss=2.66]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.66276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 23.11batch/s, train_acc=0.0894, train_logloss=2.44, train_loss=2.49]\n",
      "Valid Epoch 12: 100%|██████████| 2/2 [00:00<00:00, 28.33batch/s, valid_acc=0.129, valid_logloss=2.52, valid_loss=2.66]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.65854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 23.17batch/s, train_acc=0.0894, train_logloss=2.45, train_loss=2.63]\n",
      "Valid Epoch 13: 100%|██████████| 2/2 [00:00<00:00, 28.20batch/s, valid_acc=0.129, valid_logloss=2.52, valid_loss=2.65]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.65231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 23.18batch/s, train_acc=0.0894, train_logloss=2.44, train_loss=2.56]\n",
      "Valid Epoch 14: 100%|██████████| 2/2 [00:00<00:00, 28.17batch/s, valid_acc=0.129, valid_logloss=2.51, valid_loss=2.64]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.64321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 23.19batch/s, train_acc=0.0877, train_logloss=2.44, train_loss=2.54]\n",
      "Valid Epoch 15: 100%|██████████| 2/2 [00:00<00:00, 28.33batch/s, valid_acc=0.129, valid_logloss=2.51, valid_loss=2.63]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.63183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 23.12batch/s, train_acc=0.0794, train_logloss=2.44, train_loss=2.5] \n",
      "Valid Epoch 16: 100%|██████████| 2/2 [00:00<00:00, 28.47batch/s, valid_acc=0.129, valid_logloss=2.5, valid_loss=2.62]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.61741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 23.10batch/s, train_acc=0.0713, train_logloss=2.44, train_loss=2.55]\n",
      "Valid Epoch 17: 100%|██████████| 2/2 [00:00<00:00, 27.66batch/s, valid_acc=0.129, valid_logloss=2.49, valid_loss=2.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.60123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 23.08batch/s, train_acc=0.0654, train_logloss=2.43, train_loss=2.46]\n",
      "Valid Epoch 18: 100%|██████████| 2/2 [00:00<00:00, 27.95batch/s, valid_acc=0.129, valid_logloss=2.49, valid_loss=2.58]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.58460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.85batch/s, train_acc=0.0705, train_logloss=2.43, train_loss=2.49]\n",
      "Valid Epoch 19: 100%|██████████| 2/2 [00:00<00:00, 27.11batch/s, valid_acc=0.129, valid_logloss=2.48, valid_loss=2.57]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.56892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.98batch/s, train_acc=0.1, train_logloss=2.42, train_loss=2.44]   \n",
      "Valid Epoch 20: 100%|██████████| 2/2 [00:00<00:00, 27.83batch/s, valid_acc=0.129, valid_logloss=2.48, valid_loss=2.57]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.56743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 23.03batch/s, train_acc=0.1, train_logloss=2.42, train_loss=2.51]   \n",
      "Valid Epoch 21: 100%|██████████| 2/2 [00:00<00:00, 27.96batch/s, valid_acc=0.129, valid_logloss=2.48, valid_loss=2.57]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.56561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 23.07batch/s, train_acc=0.0993, train_logloss=2.42, train_loss=2.52]\n",
      "Valid Epoch 22: 100%|██████████| 2/2 [00:00<00:00, 27.84batch/s, valid_acc=0.129, valid_logloss=2.47, valid_loss=2.56]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.56292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.55batch/s, train_acc=0.0975, train_logloss=2.42, train_loss=2.52]\n",
      "Valid Epoch 23: 100%|██████████| 2/2 [00:00<00:00, 27.40batch/s, valid_acc=0.129, valid_logloss=2.47, valid_loss=2.56]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.55895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.35batch/s, train_acc=0.101, train_logloss=2.42, train_loss=2.5]  \n",
      "Valid Epoch 24: 100%|██████████| 2/2 [00:00<00:00, 27.99batch/s, valid_acc=0.129, valid_logloss=2.47, valid_loss=2.55]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.55326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.39batch/s, train_acc=0.093, train_logloss=2.42, train_loss=2.51] \n",
      "Valid Epoch 25: 100%|██████████| 2/2 [00:00<00:00, 27.58batch/s, valid_acc=0.129, valid_logloss=2.47, valid_loss=2.55]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.54624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.78batch/s, train_acc=0.0988, train_logloss=2.42, train_loss=2.46]\n",
      "Valid Epoch 26: 100%|██████████| 2/2 [00:00<00:00, 28.00batch/s, valid_acc=0.129, valid_logloss=2.46, valid_loss=2.54]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.53771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.67batch/s, train_acc=0.0966, train_logloss=2.43, train_loss=2.49]\n",
      "Valid Epoch 27: 100%|██████████| 2/2 [00:00<00:00, 28.18batch/s, valid_acc=0.129, valid_logloss=2.46, valid_loss=2.53]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.52689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 20.04batch/s, train_acc=0.0763, train_logloss=2.42, train_loss=2.46]\n",
      "Valid Epoch 28: 100%|██████████| 2/2 [00:00<00:00, 27.97batch/s, valid_acc=0.129, valid_logloss=2.45, valid_loss=2.52]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.51661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 23.00batch/s, train_acc=0.0843, train_logloss=2.42, train_loss=2.46]\n",
      "Valid Epoch 29: 100%|██████████| 2/2 [00:00<00:00, 28.33batch/s, valid_acc=0.129, valid_logloss=2.45, valid_loss=2.51]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.50652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.98batch/s, train_acc=0.104, train_logloss=2.41, train_loss=2.43] \n",
      "Valid Epoch 30: 100%|██████████| 2/2 [00:00<00:00, 27.36batch/s, valid_acc=0.129, valid_logloss=2.45, valid_loss=2.51]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.50556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 23.01batch/s, train_acc=0.0966, train_logloss=2.41, train_loss=2.49]\n",
      "Valid Epoch 31: 100%|██████████| 2/2 [00:00<00:00, 23.06batch/s, valid_acc=0.129, valid_logloss=2.45, valid_loss=2.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.50442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.97batch/s, train_acc=0.0983, train_logloss=2.41, train_loss=2.47]\n",
      "Valid Epoch 32: 100%|██████████| 2/2 [00:00<00:00, 27.52batch/s, valid_acc=0.129, valid_logloss=2.45, valid_loss=2.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.50272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.98batch/s, train_acc=0.0992, train_logloss=2.41, train_loss=2.45]\n",
      "Valid Epoch 33: 100%|██████████| 2/2 [00:00<00:00, 28.11batch/s, valid_acc=0.129, valid_logloss=2.45, valid_loss=2.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.50051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.95batch/s, train_acc=0.0936, train_logloss=2.41, train_loss=2.4] \n",
      "Valid Epoch 34: 100%|██████████| 2/2 [00:00<00:00, 28.25batch/s, valid_acc=0.129, valid_logloss=2.44, valid_loss=2.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.49738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.97batch/s, train_acc=0.0872, train_logloss=2.41, train_loss=2.45]\n",
      "Valid Epoch 35: 100%|██████████| 2/2 [00:00<00:00, 28.25batch/s, valid_acc=0.129, valid_logloss=2.44, valid_loss=2.49]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.49307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.97batch/s, train_acc=0.0919, train_logloss=2.41, train_loss=2.43]\n",
      "Valid Epoch 36: 100%|██████████| 2/2 [00:00<00:00, 27.97batch/s, valid_acc=0.129, valid_logloss=2.44, valid_loss=2.49]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.48819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 23.04batch/s, train_acc=0.0788, train_logloss=2.41, train_loss=2.41]\n",
      "Valid Epoch 37: 100%|██████████| 2/2 [00:00<00:00, 27.96batch/s, valid_acc=0.129, valid_logloss=2.44, valid_loss=2.48]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.48232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.92batch/s, train_acc=0.0788, train_logloss=2.41, train_loss=2.41]\n",
      "Valid Epoch 38: 100%|██████████| 2/2 [00:00<00:00, 27.68batch/s, valid_acc=0.129, valid_logloss=2.43, valid_loss=2.48]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.47649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.71batch/s, train_acc=0.0857, train_logloss=2.41, train_loss=2.39]\n",
      "Valid Epoch 39: 100%|██████████| 2/2 [00:00<00:00, 28.12batch/s, valid_acc=0.129, valid_logloss=2.43, valid_loss=2.47]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.47031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.60batch/s, train_acc=0.1, train_logloss=2.4, train_loss=2.4]     \n",
      "Valid Epoch 40: 100%|██████████| 2/2 [00:00<00:00, 27.05batch/s, valid_acc=0.129, valid_logloss=2.43, valid_loss=2.47]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.46989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.66batch/s, train_acc=0.106, train_logloss=2.4, train_loss=2.37]  \n",
      "Valid Epoch 41: 100%|██████████| 2/2 [00:00<00:00, 26.53batch/s, valid_acc=0.129, valid_logloss=2.43, valid_loss=2.47]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.46919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.94batch/s, train_acc=0.106, train_logloss=2.4, train_loss=2.37]  \n",
      "Valid Epoch 42: 100%|██████████| 2/2 [00:00<00:00, 27.56batch/s, valid_acc=0.129, valid_logloss=2.43, valid_loss=2.47]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.46826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.78batch/s, train_acc=0.095, train_logloss=2.41, train_loss=2.41] \n",
      "Valid Epoch 43: 100%|██████████| 2/2 [00:00<00:00, 25.96batch/s, valid_acc=0.129, valid_logloss=2.43, valid_loss=2.47]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.46685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.89batch/s, train_acc=0.0994, train_logloss=2.41, train_loss=2.41]\n",
      "Valid Epoch 44: 100%|██████████| 2/2 [00:00<00:00, 27.94batch/s, valid_acc=0.129, valid_logloss=2.43, valid_loss=2.46]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.46452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.93batch/s, train_acc=0.0988, train_logloss=2.41, train_loss=2.38]\n",
      "Valid Epoch 45: 100%|██████████| 2/2 [00:00<00:00, 28.23batch/s, valid_acc=0.129, valid_logloss=2.43, valid_loss=2.46]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.46207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.99batch/s, train_acc=0.0948, train_logloss=2.41, train_loss=2.37]\n",
      "Valid Epoch 46: 100%|██████████| 2/2 [00:00<00:00, 27.24batch/s, valid_acc=0.129, valid_logloss=2.43, valid_loss=2.46]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.45910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.94batch/s, train_acc=0.0995, train_logloss=2.41, train_loss=2.37]\n",
      "Valid Epoch 47: 100%|██████████| 2/2 [00:00<00:00, 27.32batch/s, valid_acc=0.129, valid_logloss=2.43, valid_loss=2.46]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.45612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.81batch/s, train_acc=0.104, train_logloss=2.41, train_loss=2.37] \n",
      "Valid Epoch 48: 100%|██████████| 2/2 [00:00<00:00, 27.86batch/s, valid_acc=0.129, valid_logloss=2.43, valid_loss=2.45]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.45295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.88batch/s, train_acc=0.0995, train_logloss=2.41, train_loss=2.36]\n",
      "Valid Epoch 49: 100%|██████████| 2/2 [00:00<00:00, 27.69batch/s, valid_acc=0.129, valid_logloss=2.42, valid_loss=2.45]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.44915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.67batch/s, train_acc=0.0983, train_logloss=2.4, train_loss=2.35] \n",
      "Valid Epoch 50: 100%|██████████| 2/2 [00:00<00:00, 27.52batch/s, valid_acc=0.129, valid_logloss=2.42, valid_loss=2.45]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.44876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.73batch/s, train_acc=0.0966, train_logloss=2.4, train_loss=2.36] \n",
      "Valid Epoch 51: 100%|██████████| 2/2 [00:00<00:00, 27.14batch/s, valid_acc=0.129, valid_logloss=2.42, valid_loss=2.45]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.44830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.62batch/s, train_acc=0.101, train_logloss=2.4, train_loss=2.35]  \n",
      "Valid Epoch 52: 100%|██████████| 2/2 [00:00<00:00, 26.19batch/s, valid_acc=0.129, valid_logloss=2.42, valid_loss=2.45]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.44772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.10batch/s, train_acc=0.103, train_logloss=2.4, train_loss=2.34]  \n",
      "Valid Epoch 53: 100%|██████████| 2/2 [00:00<00:00, 24.95batch/s, valid_acc=0.129, valid_logloss=2.42, valid_loss=2.45]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.44661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.82batch/s, train_acc=0.1, train_logloss=2.4, train_loss=2.35]    \n",
      "Valid Epoch 54: 100%|██████████| 2/2 [00:00<00:00, 28.08batch/s, valid_acc=0.129, valid_logloss=2.42, valid_loss=2.45]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.44525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.60batch/s, train_acc=0.0976, train_logloss=2.4, train_loss=2.36] \n",
      "Valid Epoch 55: 100%|██████████| 2/2 [00:00<00:00, 27.70batch/s, valid_acc=0.129, valid_logloss=2.42, valid_loss=2.44]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.44392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.96batch/s, train_acc=0.0996, train_logloss=2.41, train_loss=2.35]\n",
      "Valid Epoch 56: 100%|██████████| 2/2 [00:00<00:00, 27.83batch/s, valid_acc=0.0684, valid_logloss=2.42, valid_loss=2.44]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.44224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.80batch/s, train_acc=0.0984, train_logloss=2.41, train_loss=2.33]\n",
      "Valid Epoch 57: 100%|██████████| 2/2 [00:00<00:00, 27.77batch/s, valid_acc=0.0293, valid_logloss=2.42, valid_loss=2.44]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.44037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.98batch/s, train_acc=0.104, train_logloss=2.41, train_loss=2.33] \n",
      "Valid Epoch 58: 100%|██████████| 2/2 [00:00<00:00, 28.25batch/s, valid_acc=0.00781, valid_logloss=2.42, valid_loss=2.44]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.43763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.66batch/s, train_acc=0.0996, train_logloss=2.41, train_loss=2.33]\n",
      "Valid Epoch 59: 100%|██████████| 2/2 [00:00<00:00, 28.30batch/s, valid_acc=0.00781, valid_logloss=2.42, valid_loss=2.44]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.43511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.72batch/s, train_acc=0.107, train_logloss=2.4, train_loss=2.31]  \n",
      "Valid Epoch 60: 100%|██████████| 2/2 [00:00<00:00, 28.25batch/s, valid_acc=0.00781, valid_logloss=2.42, valid_loss=2.43]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.43487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.97batch/s, train_acc=0.0989, train_logloss=2.4, train_loss=2.33] \n",
      "Valid Epoch 61: 100%|██████████| 2/2 [00:00<00:00, 24.29batch/s, valid_acc=0.00781, valid_logloss=2.42, valid_loss=2.43]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.43473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.59batch/s, train_acc=0.109, train_logloss=2.4, train_loss=2.32]  \n",
      "Valid Epoch 62: 100%|██████████| 2/2 [00:00<00:00, 27.89batch/s, valid_acc=0.00781, valid_logloss=2.42, valid_loss=2.43]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.43440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.97batch/s, train_acc=0.104, train_logloss=2.4, train_loss=2.32]  \n",
      "Valid Epoch 63: 100%|██████████| 2/2 [00:00<00:00, 28.06batch/s, valid_acc=0.00781, valid_logloss=2.42, valid_loss=2.43]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.43407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.88batch/s, train_acc=0.105, train_logloss=2.4, train_loss=2.32]  \n",
      "Valid Epoch 64: 100%|██████████| 2/2 [00:00<00:00, 28.32batch/s, valid_acc=0.00781, valid_logloss=2.42, valid_loss=2.43]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.43336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.93batch/s, train_acc=0.105, train_logloss=2.4, train_loss=2.32]  \n",
      "Valid Epoch 65: 100%|██████████| 2/2 [00:00<00:00, 28.19batch/s, valid_acc=0.00781, valid_logloss=2.42, valid_loss=2.43]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.43158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.76batch/s, train_acc=0.0982, train_logloss=2.41, train_loss=2.33]\n",
      "Valid Epoch 66: 100%|██████████| 2/2 [00:00<00:00, 27.86batch/s, valid_acc=0.00781, valid_logloss=2.42, valid_loss=2.43]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.43013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 21.88batch/s, train_acc=0.106, train_logloss=2.41, train_loss=2.31] \n",
      "Valid Epoch 67: 100%|██████████| 2/2 [00:00<00:00, 27.89batch/s, valid_acc=0.00781, valid_logloss=2.42, valid_loss=2.43]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.42857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.64batch/s, train_acc=0.106, train_logloss=2.41, train_loss=2.31] \n",
      "Valid Epoch 68: 100%|██████████| 2/2 [00:00<00:00, 25.17batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.43]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.42668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.59batch/s, train_acc=0.102, train_logloss=2.41, train_loss=2.3]  \n",
      "Valid Epoch 69: 100%|██████████| 2/2 [00:00<00:00, 28.28batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.43]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.42593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.62batch/s, train_acc=0.102, train_logloss=2.4, train_loss=2.3]   \n",
      "Valid Epoch 70: 100%|██████████| 2/2 [00:00<00:00, 21.10batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.43]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.42580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.61batch/s, train_acc=0.0831, train_logloss=2.4, train_loss=2.3]   \n",
      "Valid Epoch 71: 100%|██████████| 2/2 [00:00<00:00, 27.04batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.43]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.42576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.91batch/s, train_acc=0.0821, train_logloss=2.4, train_loss=2.3]   \n",
      "Valid Epoch 72: 100%|██████████| 2/2 [00:00<00:00, 28.57batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.43]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.42545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 20.07batch/s, train_acc=0.0818, train_logloss=2.4, train_loss=2.3]   \n",
      "Valid Epoch 73: 100%|██████████| 2/2 [00:00<00:00, 27.20batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.43]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.42500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.89batch/s, train_acc=0.101, train_logloss=2.4, train_loss=2.29]  \n",
      "Valid Epoch 74: 100%|██████████| 2/2 [00:00<00:00, 28.17batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.42457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.88batch/s, train_acc=0.0725, train_logloss=2.4, train_loss=2.3]   \n",
      "Valid Epoch 75: 100%|██████████| 2/2 [00:00<00:00, 27.46batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.42372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.93batch/s, train_acc=0.102, train_logloss=2.4, train_loss=2.3]    \n",
      "Valid Epoch 76: 100%|██████████| 2/2 [00:00<00:00, 28.67batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.42]\n",
      "100%|██████████| 24/24 [00:01<00:00, 22.90batch/s, train_acc=0.108, train_logloss=2.41, train_loss=2.3]   \n",
      "Valid Epoch 77: 100%|██████████| 2/2 [00:00<00:00, 27.92batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.42259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.69batch/s, train_acc=0.106, train_logloss=2.41, train_loss=2.29] \n",
      "Valid Epoch 78: 100%|██████████| 2/2 [00:00<00:00, 27.84batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.42197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.86batch/s, train_acc=0.106, train_logloss=2.41, train_loss=2.29] \n",
      "Valid Epoch 79: 100%|██████████| 2/2 [00:00<00:00, 27.36batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.42135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.81batch/s, train_acc=0.106, train_logloss=2.4, train_loss=2.28]  \n",
      "Valid Epoch 80: 100%|██████████| 2/2 [00:00<00:00, 26.39batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.42130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.79batch/s, train_acc=0.106, train_logloss=2.4, train_loss=2.29]  \n",
      "Valid Epoch 81: 100%|██████████| 2/2 [00:00<00:00, 27.57batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.42122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.44batch/s, train_acc=0.106, train_logloss=2.4, train_loss=2.29]  \n",
      "Valid Epoch 82: 100%|██████████| 2/2 [00:00<00:00, 27.95batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.42111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.58batch/s, train_acc=0.106, train_logloss=2.4, train_loss=2.28]  \n",
      "Valid Epoch 83: 100%|██████████| 2/2 [00:00<00:00, 27.92batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.42093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.41batch/s, train_acc=0.106, train_logloss=2.4, train_loss=2.29]  \n",
      "Valid Epoch 84: 100%|██████████| 2/2 [00:00<00:00, 28.62batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.42082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.85batch/s, train_acc=0.106, train_logloss=2.4, train_loss=2.28]  \n",
      "Valid Epoch 85: 100%|██████████| 2/2 [00:00<00:00, 27.07batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.42022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.54batch/s, train_acc=0.106, train_logloss=2.4, train_loss=2.28]  \n",
      "Valid Epoch 86: 100%|██████████| 2/2 [00:00<00:00, 27.15batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.41973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 21.54batch/s, train_acc=0.106, train_logloss=2.41, train_loss=2.28] \n",
      "Valid Epoch 87: 100%|██████████| 2/2 [00:00<00:00, 27.69batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.41937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.61batch/s, train_acc=0.106, train_logloss=2.41, train_loss=2.28] \n",
      "Valid Epoch 88: 100%|██████████| 2/2 [00:00<00:00, 27.42batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.41847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.62batch/s, train_acc=0.106, train_logloss=2.41, train_loss=2.28] \n",
      "Valid Epoch 89: 100%|██████████| 2/2 [00:00<00:00, 27.89batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.41809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.63batch/s, train_acc=0.106, train_logloss=2.4, train_loss=2.27]  \n",
      "Valid Epoch 90: 100%|██████████| 2/2 [00:00<00:00, 27.18batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.41801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.70batch/s, train_acc=0.106, train_logloss=2.4, train_loss=2.27]  \n",
      "Valid Epoch 91: 100%|██████████| 2/2 [00:00<00:00, 27.22batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.41787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.76batch/s, train_acc=0.106, train_logloss=2.4, train_loss=2.27]  \n",
      "Valid Epoch 92: 100%|██████████| 2/2 [00:00<00:00, 27.22batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.41770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.65batch/s, train_acc=0.106, train_logloss=2.4, train_loss=2.27]  \n",
      "Valid Epoch 93: 100%|██████████| 2/2 [00:00<00:00, 27.94batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.42]\n",
      "100%|██████████| 24/24 [00:01<00:00, 22.66batch/s, train_acc=0.106, train_logloss=2.4, train_loss=2.27]  \n",
      "Valid Epoch 94: 100%|██████████| 2/2 [00:00<00:00, 27.52batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.42]\n",
      "100%|██████████| 24/24 [00:01<00:00, 22.82batch/s, train_acc=0.106, train_logloss=2.4, train_loss=2.27]  \n",
      "Valid Epoch 95: 100%|██████████| 2/2 [00:00<00:00, 23.38batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.41736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.53batch/s, train_acc=0.106, train_logloss=2.4, train_loss=2.27]  \n",
      "Valid Epoch 96: 100%|██████████| 2/2 [00:00<00:00, 27.26batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.41726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.70batch/s, train_acc=0.106, train_logloss=2.41, train_loss=2.27] \n",
      "Valid Epoch 97: 100%|██████████| 2/2 [00:00<00:00, 27.00batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.41641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.68batch/s, train_acc=0.106, train_logloss=2.41, train_loss=2.27] \n",
      "Valid Epoch 98: 100%|██████████| 2/2 [00:00<00:00, 27.81batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.41536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.48batch/s, train_acc=0.106, train_logloss=2.41, train_loss=2.27] \n",
      "Valid Epoch 99: 100%|██████████| 2/2 [00:00<00:00, 26.58batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.41]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.41495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.79batch/s, train_acc=0.106, train_logloss=2.4, train_loss=2.26]  \n",
      "Valid Epoch 100: 100%|██████████| 2/2 [00:00<00:00, 27.79batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.41]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.41491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.67batch/s, train_acc=0.106, train_logloss=2.4, train_loss=2.26]  \n",
      "Valid Epoch 101: 100%|██████████| 2/2 [00:00<00:00, 27.59batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.41]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.41486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.72batch/s, train_acc=0.106, train_logloss=2.4, train_loss=2.26]  \n",
      "Valid Epoch 102: 100%|██████████| 2/2 [00:00<00:00, 28.33batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.41]\n",
      "100%|██████████| 24/24 [00:01<00:00, 22.79batch/s, train_acc=0.106, train_logloss=2.4, train_loss=2.26]  \n",
      "Valid Epoch 103: 100%|██████████| 2/2 [00:00<00:00, 27.51batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.41]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.41484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.86batch/s, train_acc=0.106, train_logloss=2.4, train_loss=2.26]  \n",
      "Valid Epoch 104: 100%|██████████| 2/2 [00:00<00:00, 27.30batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.41]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.41480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.50batch/s, train_acc=0.106, train_logloss=2.4, train_loss=2.26]  \n",
      "Valid Epoch 105: 100%|██████████| 2/2 [00:00<00:00, 28.48batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.42]\n",
      "100%|██████████| 24/24 [00:01<00:00, 22.74batch/s, train_acc=0.106, train_logloss=2.4, train_loss=2.26]  \n",
      "Valid Epoch 106: 100%|██████████| 2/2 [00:00<00:00, 23.00batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.42]\n",
      "100%|██████████| 24/24 [00:01<00:00, 22.82batch/s, train_acc=0.106, train_logloss=2.41, train_loss=2.26] \n",
      "Valid Epoch 107: 100%|██████████| 2/2 [00:00<00:00, 28.25batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.41]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.41469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.81batch/s, train_acc=0.106, train_logloss=2.41, train_loss=2.26] \n",
      "Valid Epoch 108: 100%|██████████| 2/2 [00:00<00:00, 28.07batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.41]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.41410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.74batch/s, train_acc=0.106, train_logloss=2.41, train_loss=2.26] \n",
      "Valid Epoch 109: 100%|██████████| 2/2 [00:00<00:00, 28.31batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.41]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.41328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.83batch/s, train_acc=0.106, train_logloss=2.4, train_loss=2.26]  \n",
      "Valid Epoch 110: 100%|██████████| 2/2 [00:00<00:00, 27.55batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.41]\n",
      "100%|██████████| 24/24 [00:01<00:00, 22.70batch/s, train_acc=0.106, train_logloss=2.4, train_loss=2.26]  \n",
      "Valid Epoch 111: 100%|██████████| 2/2 [00:00<00:00, 27.91batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.41]\n",
      "100%|██████████| 24/24 [00:01<00:00, 22.35batch/s, train_acc=0.106, train_logloss=2.4, train_loss=2.26]  \n",
      "Valid Epoch 112: 100%|██████████| 2/2 [00:00<00:00, 27.63batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.41]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.41324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.39batch/s, train_acc=0.106, train_logloss=2.4, train_loss=2.26]  \n",
      "Valid Epoch 113: 100%|██████████| 2/2 [00:00<00:00, 28.30batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.41]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.41295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.65batch/s, train_acc=0.106, train_logloss=2.4, train_loss=2.26]  \n",
      "Valid Epoch 114: 100%|██████████| 2/2 [00:00<00:00, 27.85batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.41]\n",
      "100%|██████████| 24/24 [00:01<00:00, 22.39batch/s, train_acc=0.106, train_logloss=2.4, train_loss=2.26]  \n",
      "Valid Epoch 115: 100%|██████████| 2/2 [00:00<00:00, 26.62batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.41]\n",
      "100%|██████████| 24/24 [00:01<00:00, 22.59batch/s, train_acc=0.106, train_logloss=2.4, train_loss=2.26]  \n",
      "Valid Epoch 116: 100%|██████████| 2/2 [00:00<00:00, 28.69batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.41]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.41292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.61batch/s, train_acc=0.106, train_logloss=2.41, train_loss=2.26] \n",
      "Valid Epoch 117: 100%|██████████| 2/2 [00:00<00:00, 28.27batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.41]\n",
      "100%|██████████| 24/24 [00:01<00:00, 22.82batch/s, train_acc=0.106, train_logloss=2.41, train_loss=2.26] \n",
      "Valid Epoch 118: 100%|██████████| 2/2 [00:00<00:00, 28.30batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.41]\n",
      "100%|██████████| 24/24 [00:01<00:00, 19.97batch/s, train_acc=0.106, train_logloss=2.41, train_loss=2.26] \n",
      "Valid Epoch 119: 100%|██████████| 2/2 [00:00<00:00, 27.56batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.41]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.41261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.79batch/s, train_acc=0.106, train_logloss=2.4, train_loss=2.25]  \n",
      "Valid Epoch 120: 100%|██████████| 2/2 [00:00<00:00, 28.08batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.41]\n",
      "100%|██████████| 24/24 [00:01<00:00, 22.84batch/s, train_acc=0.106, train_logloss=2.4, train_loss=2.25]  \n",
      "Valid Epoch 121: 100%|██████████| 2/2 [00:00<00:00, 27.35batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.41]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST VALID LOSS : 2.41261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.84batch/s, train_acc=0.106, train_logloss=2.4, train_loss=2.25]  \n",
      "Valid Epoch 122: 100%|██████████| 2/2 [00:00<00:00, 27.98batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.41]\n",
      "100%|██████████| 24/24 [00:01<00:00, 22.90batch/s, train_acc=0.106, train_logloss=2.4, train_loss=2.25]  \n",
      "Valid Epoch 123: 100%|██████████| 2/2 [00:00<00:00, 27.77batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.41]\n",
      "100%|██████████| 24/24 [00:01<00:00, 22.72batch/s, train_acc=0.106, train_logloss=2.4, train_loss=2.25]  \n",
      "Valid Epoch 124: 100%|██████████| 2/2 [00:00<00:00, 27.65batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.41]\n",
      "100%|██████████| 24/24 [00:01<00:00, 22.75batch/s, train_acc=0.106, train_logloss=2.4, train_loss=2.26]  \n",
      "Valid Epoch 125: 100%|██████████| 2/2 [00:00<00:00, 26.81batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.41]\n",
      "100%|██████████| 24/24 [00:01<00:00, 22.70batch/s, train_acc=0.106, train_logloss=2.4, train_loss=2.26]  \n",
      "Valid Epoch 126: 100%|██████████| 2/2 [00:00<00:00, 27.40batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.41]\n",
      "100%|██████████| 24/24 [00:01<00:00, 22.77batch/s, train_acc=0.106, train_logloss=2.41, train_loss=2.25] \n",
      "Valid Epoch 127: 100%|██████████| 2/2 [00:00<00:00, 27.38batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.41]\n",
      "100%|██████████| 24/24 [00:01<00:00, 22.82batch/s, train_acc=0.106, train_logloss=2.41, train_loss=2.26] \n",
      "Valid Epoch 128: 100%|██████████| 2/2 [00:00<00:00, 27.58batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.41]\n",
      "100%|██████████| 24/24 [00:01<00:00, 22.77batch/s, train_acc=0.106, train_logloss=2.41, train_loss=2.26] \n",
      "Valid Epoch 129: 100%|██████████| 2/2 [00:00<00:00, 28.32batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.41]\n",
      "100%|██████████| 24/24 [00:01<00:00, 22.85batch/s, train_acc=0.106, train_logloss=2.4, train_loss=2.25]  \n",
      "Valid Epoch 130: 100%|██████████| 2/2 [00:00<00:00, 28.33batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.41]\n",
      "100%|██████████| 24/24 [00:01<00:00, 22.88batch/s, train_acc=0.106, train_logloss=2.4, train_loss=2.25]  \n",
      "Valid Epoch 131: 100%|██████████| 2/2 [00:00<00:00, 27.82batch/s, valid_acc=0.00781, valid_logloss=2.41, valid_loss=2.41]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EARLY_STOPPING!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# transfer learning\n",
    "\n",
    "transferred_best_models = []\n",
    "\n",
    "EARLY_STOPPING_EPOCH = 10\n",
    "\n",
    "softmax = torch.nn.Softmax(-1)\n",
    "\n",
    "optimizer = optim.Adam(trans_model.parameters(), lr=lr)\n",
    "lr_sched = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=1, eta_min=0.001, last_epoch=-1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "valid_acc_max = 0\n",
    "valid_early_stop = 0\n",
    "valid_best_loss = float('inf')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_acc_list = []\n",
    "    train_logloss_list = []\n",
    "    with tqdm(dataset1_train_dataloader, total=dataset1_train_dataloader.__len__(), unit=\"batch\") as train_bar:\n",
    "        for sample in train_bar:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            datas, labels = sample\n",
    "            datas = datas.to(device)\n",
    "            labels = labels.to(dtype=torch.long).to(device)\n",
    "            trans_model.train()\n",
    "            with torch.set_grad_enabled(True):\n",
    "                outputs = trans_model(datas)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # log loss\n",
    "                probs = softmax(outputs)\n",
    "                refs = labels.cpu().detach().clone().numpy()\n",
    "                probs = probs.cpu().detach().clone().numpy()\n",
    "                logloss = log_loss(refs, probs, labels = np.arange(0,11))\n",
    "                train_logloss_list.append(logloss)\n",
    "                train_logloss = np.mean(train_logloss_list)\n",
    "\n",
    "                preds = torch.argmax(outputs, dim = 1)\n",
    "                preds = preds.cpu().detach().numpy()\n",
    "                refs = labels.cpu().detach().numpy()\n",
    "                batch_acc = (refs == preds).mean()\n",
    "                train_acc_list.append(batch_acc)\n",
    "                train_acc = np.mean(train_acc_list)\n",
    "                \n",
    "            train_bar.set_postfix(train_loss= loss.item(), train_acc = train_acc, train_logloss = train_logloss)\n",
    "            \n",
    "       \n",
    "    valid_acc_list = []\n",
    "    valid_logloss_list = []\n",
    "    with tqdm(dataset1_val_dataloader, total=dataset1_val_dataloader.__len__(), unit=\"batch\") as valid_bar:\n",
    "        for sample in valid_bar:\n",
    "            valid_bar.set_description(f\"Valid Epoch {epoch}\")\n",
    "            optimizer.zero_grad()\n",
    "            datas, labels = sample\n",
    "            datas = datas.to(device)\n",
    "            labels = labels.to(dtype=torch.long).to(device)\n",
    "\n",
    "            trans_model.eval()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = trans_model(datas) # bsz, nlabel\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # log loss\n",
    "                probs = softmax(outputs)\n",
    "                refs = labels.cpu().detach().clone().numpy()\n",
    "                probs = probs.cpu().detach().clone().numpy()\n",
    "                logloss = log_loss(refs, probs, labels = np.arange(0,11))\n",
    "                valid_logloss_list.append(logloss)\n",
    "                valid_logloss = np.mean(valid_logloss_list)\n",
    "\n",
    "                preds = torch.argmax(outputs, dim = 1)\n",
    "                preds = preds.cpu().detach().numpy()\n",
    "                refs = labels.cpu().detach().numpy()\n",
    "                batch_acc = (refs == preds).mean()\n",
    "                valid_acc_list.append(batch_acc)\n",
    "                valid_acc = np.mean(valid_acc_list)\n",
    "\n",
    "            valid_bar.set_postfix(valid_loss= loss.item(), valid_acc = valid_acc, valid_logloss = valid_logloss)\n",
    "            \n",
    "    # early stopping\n",
    "    if loss.item() < valid_best_loss:\n",
    "        print(f\"\\nBEST VALID LOSS : {loss.item():.5f}\")\n",
    "        valid_best_loss = loss.item()\n",
    "        valid_early_stop = 0\n",
    "    else:\n",
    "        valid_early_stop += 1\n",
    "        if valid_early_stop >= EARLY_STOPPING_EPOCH:\n",
    "            print(\"\\nEARLY_STOPPING!!\")\n",
    "            break\n",
    "            \n",
    "    lr_sched.step()\n",
    "    \n",
    "    if valid_acc_max < valid_acc:\n",
    "        valid_acc_max = valid_acc\n",
    "        transferred_best_model = trans_model\n",
    "        torch.save(transferred_best_model.state_dict(), f'./transferred_best_model_freeze.pth')\n",
    "\n",
    "    transferred_best_models.append(transferred_best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "d12a797b",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_sample = pd.read_csv('submission_sample.csv', index_col = 0)\n",
    "\n",
    "# dataset1의 test 데이터를 사용한 일반화 성능 확인\n",
    "\n",
    "optimizer = optim.Adam(transferred_best_models[-1].parameters(), lr=lr)\n",
    "lr_sched = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=1, eta_min=0.001, last_epoch=-1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 가장 최근 모델로 예측\n",
    "for i, model in enumerate(transferred_best_models[-1:]):\n",
    "\n",
    "    model.eval()\n",
    "    predicted = []\n",
    "    with torch.no_grad():\n",
    "        for idx, x in enumerate(dataset1_test_dataloader):\n",
    "            x = x[0].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x.float())\n",
    "\n",
    "            _, preds = torch.max(output, 1)\n",
    "            predicted.extend(preds.cpu().numpy())\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    pd_preds = pd.DataFrame(predicted, columns=['predicted value'], index=submission_sample.index.copy())\n",
    "    pd_preds['predicted value'] = 'class' + pd_preds['predicted value'].astype(str)\n",
    "    pd_preds.to_csv(f'submission_{timestr}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
